---
title: "homework 6"
author: "Xiaoyu Wu"
date: "2023-11-18"
output: github_document
---

```{r,message=FALSE}
library(dplyr)
library(broom)
library(purrr)
library(tidyr)
library(ggplot2)
library(boot)
library(forcats)
library(modelr)
```

## Problem One 

```{r, warning=FALSE}
homicide_data_tidy= read.csv("./data/homicide-data.csv") |> 
# Load the data from a CSV file
  mutate(city_state = paste(city, state, sep = ", ")) |> 
# Create city_state variable
  mutate(is_solved = ifelse(disposition == "Closed by arrest", 1, 0)) |> 
# Create a binary variable indicating whether the homicide is solved
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
# Omit cities Dallas, TX; Phoenix, AZ; and Kansas City. Also omit Tulsa, AL. 
  victim_race %in% c("White", "Black")) |>
# Limit your analysis those for whom victim_race is white or black
  mutate(victim_age = as.numeric(victim_age))
# Be sure that victim_age is numeric
```

```{r}
baltimore_data = homicide_data_tidy|>
  filter(city_state == "Baltimore, MD") |> 
# Filter out the city of Baltimore, MD
  mutate(victim_sex = relevel(as.factor(victim_sex), ref = "Female")) |> 
# Ensure victim_sex is a factor with Female as reference
  mutate(victim_race = factor(victim_race)) 
# Ensure victim_race is a factor 

logistic_model = glm(is_solved ~ victim_age + victim_sex + victim_race, 
                      data = baltimore_data, 
                      family = "binomial")
# Fit logistic regression

odds_ratio_results = broom::tidy(logistic_model, conf.int = FALSE) |> 
  filter(term == "victim_sexMale") |> 
# Comparing male victims to female victims keeping all other variables fixed
  mutate(
    OR = exp(estimate),
    LowerCI = exp(estimate - 1.96 * std.error),
    UpperCI = exp(estimate + 1.96 * std.error)
  )
# Calculate Odds Ratio and its Confidence Interval

odds_ratio_results
```

```{r}
fit_glm_city = function(city_data) {
  fit_logistic = glm(is_solved ~ victim_age + victim_race + victim_sex, data = city_data, family = binomial())
  tidy_result = fit_logistic|>
    broom::tidy()|>
    filter(term == "victim_sexMale")|>
    mutate(
      OR = exp(estimate),
      LowerCI = exp(estimate - 1.96 * std.error),
      UpperCI = exp(estimate + 1.96 * std.error)
    )|>
    select(term, OR, LowerCI, UpperCI)
}
# Create a function to fit logistic regression for a given city's data

result_list = homicide_data_tidy  |> 
  mutate(victim_race = factor(victim_race),
         victim_sex = factor(victim_sex)) |>
  group_by(city_state) |>
  nest() |>
  filter(city_state != "Tulsa, AL") |>
  mutate(glm_result = map(data, fit_glm_city)) |>
  unnest(glm_result)
# Applying the function to each city in the dataset
```

```{r}
ggplot(result_list, aes(y = OR, x = reorder(city_state, OR))) +
  geom_point() +  
# Points for OR
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), width = 0.2) +  
# Error bars for CIs
  labs(x = "City", y = "Adjusted Odds Ratio (OR)",
       title = "Estimated ORs and CIs for Solving Homicides in Each City") +
  theme_minimal() +
  coord_flip()   
# Flips the axes to make the cities display horizontally
```

#### Discussion: 
Here, we can see that Albuquerque, NM has the highest OR, that is greatest likelihood of homicide cases being solved. And New York, NY has the least OR, that is least likelihood of homicide cases being solved. Also, we can see that higher ORs are accompanied with larger confidence intervals(longer length of the error bar). 

## Problem Two 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
# Download data
```

```{r, warning=FALSE}
# Function to perform linear regression and extract the required quantities
bootstrap_function = function(data, indices) {
  # Sample the data
  boot_data = data[indices,]
  
  # Fit the linear regression model
  model = lm(tmax ~ tmin + prcp, data = boot_data)
  
  # Extract R-squared
  r_squared = glance(model)$r.squared
  
  # Extract coefficients and compute log(beta1 * beta2)
  coefs = tidy(model)
  log_product = log(coefs$estimate[2] * coefs$estimate[3])
  
  return(c(r_squared, log_product))
}

# Perform the bootstrap
set.seed(123)  # For reproducibility
bootstrap_results = boot(data = weather_df, statistic = bootstrap_function, R = 5000)

# Extract results
r_squared_dist = bootstrap_results$t[,1]
log_product_dist = bootstrap_results$t[,2]

# Plotting the distributions
ggplot() +
  geom_histogram(aes(x = r_squared_dist), binwidth = 0.01, fill = "blue", alpha = 0.7) +
  labs(title = "Distribution of R-squared Estimates", x = "R-squared", y = "Frequency") +
  theme_minimal()

ggplot() +
  geom_histogram(aes(x = log_product_dist), binwidth = 0.1, fill = "red", alpha = 0.7) +
  labs(title = "Distribution of Log(Beta1 * Beta2) Estimates", x = "Log(Beta1 * Beta2)", y = "Frequency") +
  theme_minimal()

# Calculating 95% Confidence Intervals
ci_r_squared = quantile(r_squared_dist, c(0.025, 0.975), na.rm = TRUE)
ci_log_product = quantile(log_product_dist, c(0.025, 0.975), na.rm = TRUE)

list(CI_R_squared = ci_r_squared, CI_Log_Product = ci_log_product)
```

#### Discussion of the plots 
A left-skewed distribution for the R-squared estimates suggests that most bootstrap samples yield higher R-squared values, with fewer samples resulting in lower R-squared values. This could mean that the model generally fits well, but there are instances (or specific samples) where the fit significantly worsens. The tail on the lower end could be due to outliers or certain sample combinations where the predictors do not explain the variance in the response variable as effectively. The skewness indicates that while the model is generally reliable, there are conditions under which its predictive power may decrease. 

A more pronounced left skew in the distribution of log(beta1*beta2) estimates indicates that the product of these coefficients tends to be higher in most bootstrap samples, but with a greater tendency towards lower values in some samples than observed in the R-squared distribution. This could suggest that while the relationship captured by these coefficients is generally consistent, there are more frequent instances where this relationship diminishes or is less pronounced. The greater skewness might reflect higher sensitivity of these coefficients to specific sample variations, possibly due to interactions between variables or the influence of outliers.

The distribution of R-squared estimates is much more narrower than the distribution of log(beta1*beta2) estimates, indicating that the estimates for R-squared values are more precise. 

## Problem three
```{r}
birthweight_df = read.csv("./data/birthweight.csv")|>
  mutate(babysex = ifelse(babysex == 1, 1, 0))|>
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    mrace = factor(mrace),
    frace = fct_infreq(frace),
    mrace = fct_infreq(mrace))
# Reading and transforming the data
```

#### Our model will contain wtgain, momage and smoken as predictors for bwt. 
```{r}
lm_model = lm(bwt ~ wtgain + momage + smoken, data = birthweight_df)
# Fit the model

prediction_result = birthweight_df|>
  add_predictions(lm_model, var = "fitted_values")|>
  add_residuals(lm_model, var = "residuals")
# Add predictions and residuals to the dataframe

ggplot(prediction_result, aes(x = fitted(lm_model), y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals", title = "Plot of Residuals vs Fitted Values") +
  theme_minimal()
# Plotting residuals against fitted values
```
#### Compare your model to two others:
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100)
  
cv_df =
  cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df |> 
  mutate(
    proposed_mod  = map(train, \(df) lm(bwt ~ wtgain + momage + smoken, data = df)),
    length_gestation_mod  = map(train, \(df) lm(bwt ~  blength + gaweeks, data = df)),
    interact_mod  = map(train, \(df) lm(bwt ~  bhead + blength + babysex + bhead * blength + blength* babysex + bhead* babysex + bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse_proposed = map2_dbl(proposed_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_length_gestation = map2_dbl(length_gestation_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interact = map2_dbl(interact_mod, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

#### Discussion:
In the plot, the model with interaction have the lowest RMSE, which tells it is the model with best predictivity. Our proposed model has highest rmse and least predictivity. 
